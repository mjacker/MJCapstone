{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Preparation\n",
    "For this Capstone, are eelected to be procesed two files from #[CSE-CIC-IDS2018](https://www.unb.ca/cic/datasets/ids-2018.html) those are \n",
    "- `Friday-16-02-2018_TrafficForML_CICFlowMeter.csv`\n",
    "This file contains most of Dos attacks\n",
    "\n",
    "- `Friday-02-03-2018_TrafficForML_CICFlowMeter.csv`\n",
    "This file contains most of botnet computers.\n",
    "\n",
    "since these two files contains a large malicius packages, it will help help to balance the dataset which will be uses to train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading path to dataset files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILES_PATH = []\n",
    "for path, _, file in (os.walk(\"./datasets/\")):\n",
    "    for eachFile in file:\n",
    "        DATASET_FILES_PATH.append(path + eachFile)\n",
    "DATASET_FILES_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets to PandaData Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_dataset = pd.read_csv(DATASET_FILES_PATH[0])\n",
    "\n",
    "# For Google Colab, due to memory capacity, only can handle one day dataset.\n",
    "# df_friday1 = pd.read_csv(DATASET_FILES_PATH[0])\n",
    "# df_friday2 = pd.read_csv(DATASET_FILES_PATH[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab, due to memory capacity, only can handle one day dataset.\n",
    "# df_dataset = pd.concat([df_friday1, df_friday2], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because two datasets was concatenated, then need to delete the row which cointain the second dataframe title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.drop(df_dataset.loc[df_dataset[\"Label\"] == \"Label\"].index, inplace=True)\n",
    "print(df_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unrelated columns\n",
    "Since Port, protocol and the timestand are not related to the label with those selectec machine learning, those will be droped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.drop(columns=['Dst Port', 'Protocol', 'Timestamp'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Droping rows with infinite or null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape before deleting rows: \", df_dataset.shape)\n",
    "df_dataset[df_dataset.isnull().any(axis=1)]\n",
    "df_dataset.replace([np.inf, -np.inf], np.nan)\n",
    "df_dataset.dropna(inplace=True)\n",
    "print(\"Shape after deteling rows:\", df_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Label labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dataset['Label'].unique())\n",
    "print(df_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Labels names \n",
    "To unify the labels, those malicius packages will be renamend as ones, and the normal as zeros.\n",
    "- 0 - normal package\n",
    "- 1 - malicius package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_dataset.replace(to_replace=['Benign'], value=0, inplace=True)\n",
    "df_dataset.replace(to_replace=[\"Bot\", \"DoS attacks-SlowHTTPTest\", \"DoS attacks-Hulk\"], value=1, inplace=True)\n",
    "df_dataset[df_dataset.columns[-1]].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert some string numbers to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dataset.shape)\n",
    "df_dataset.drop_duplicates(inplace=True)\n",
    "print(df_dataset.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check columns datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions labels after drop rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dataset[\"Label\"].value_counts()[[0]].sum())\n",
    "print(df_dataset[\"Label\"].value_counts()[[1]].sum())\n",
    "\n",
    "print(df_dataset.shape)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(8, 6)}\n",
    "        )\n",
    "sns.countplot(x=df_dataset[df_dataset.columns[-1]], \n",
    "              data = df_dataset,\n",
    "              palette = 'dark:#5A9_r'\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Dataset as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.to_csv(\"processed_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
